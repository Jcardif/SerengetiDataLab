{
	"name": "training-notebook",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "amlpool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "30g",
			"driverCores": 4,
			"executorMemory": "60g",
			"executorCores": 12,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "fac9f7ae-4a78-4d04-868f-429dced44a14"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/a1a27566-3e3c-42d7-a372-692095cd8521/resourceGroups/serengeti/providers/Microsoft.Synapse/workspaces/serengetidatalabb37kfc5h/bigDataPools/amlpool",
				"name": "amlpool",
				"type": "Spark",
				"endpoint": "https://serengetidatalabb37kfc5h.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/amlpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 10,
				"cores": 16,
				"memory": 110,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pip install keras"
				],
				"execution_count": 55
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pip install keras-applications"
				],
				"execution_count": 56
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\r\n",
					"\r\n",
					"spark = SparkSession \\\r\n",
					"    .builder \\\r\n",
					"    .appName(\"Create Spark Dataframe\") \\\r\n",
					"    .getOrCreate()"
				],
				"execution_count": 57
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"spark.conf.set(\"\", \"\")\r\n",
					"\r\n",
					"Database = \"defdedicated\"\r\n",
					"Server = \"serengetidatalabb37kfc5h.sql.azuresynapse.net\"\r\n",
					"User = \"sqladminuser@serengetidatalabb37kfc5h\"\r\n",
					"# Pass = sqladmin00!\r\n",
					"JdbcPort =  \"1433\"\r\n",
					"Pass = \"5R&SC4phRemt$d6S\"\r\n",
					"JdbcExtraOptions = \"encrypt=true;trustServerCertificate=true;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\r\n",
					"\r\n",
					"sqlUrl = f\"jdbc:sqlserver://{Server}:{JdbcPort};database={Database};user={User};password={Pass};${JdbcExtraOptions}\"\r\n",
					"\r\n",
					"tableName = \"train\"\r\n",
					"\r\n",
					"tempDir = \"abfss://snapshot-serengeti@serengeti.dfs.core.windows.net/\"\r\n",
					"\r\n",
					"df = spark.read \\\r\n",
					"  .format(\"jdbc\") \\\r\n",
					"  .option(\"url\", sqlUrl) \\\r\n",
					"  .option(\"tempDir\", tempDir) \\\r\n",
					"  .option(\"forwardSparkAzureStorageCredentials\", \"true\") \\\r\n",
					"  .option(\"dbTable\", tableName) \\\r\n",
					"  .load()\r\n",
					"\r\n",
					"df.show()"
				],
				"execution_count": 58
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"tableName2 = \"val\"\r\n",
					"\r\n",
					"df_val = spark.read \\\r\n",
					"  .format(\"jdbc\") \\\r\n",
					"  .option(\"url\", sqlUrl) \\\r\n",
					"  .option(\"tempDir\", tempDir) \\\r\n",
					"  .option(\"forwardSparkAzureStorageCredentials\", \"true\") \\\r\n",
					"  .option(\"dbTable\", tableName2) \\\r\n",
					"  .load()\r\n",
					"\r\n",
					"df_val.show()"
				],
				"execution_count": 59
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pip install keras --upgrade"
				],
				"execution_count": 60
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd \r\n",
					"df_train = df.toPandas()\r\n",
					"df_val = df_val.toPandas()\r\n",
					""
				],
				"execution_count": 61
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def imageURL(img_id):\r\n",
					"    return f\"https://lilablobssc.blob.core.windows.net/snapshotserengeti-unzipped/{img_id}.JPG\"\r\n",
					"\r\n",
					"df_train[\"image_link\"] = df_train[\"image_id\"].apply(imageURL)\r\n",
					"df_val[\"image_link\"] = df_val[\"image_id\"].apply(imageURL)"
				],
				"execution_count": 62
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from PIL import Image\r\n",
					"import requests\r\n",
					"\r\n",
					"url = df_train.iloc[0][\"image_link\"]\r\n",
					"response = requests.get(url)\r\n",
					"\r\n",
					"# Load an image using Image.open()\r\n",
					"img = Image.open(requests.get(url, stream=True).raw)\r\n",
					"\r\n",
					"# Show the image using img.show()\r\n",
					"img.show()"
				],
				"execution_count": 63
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"train_sub_set = df_train[\"image_link\"]\r\n",
					"val_sub_set =  df_val[\"image_link\"]"
				],
				"execution_count": 64
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import multiprocessing as mp\r\n",
					"\r\n",
					"def load_image(url, queue):\r\n",
					"    try:\r\n",
					"        response = requests.get(url)\r\n",
					"        img = Image.open(requests.get(url, stream=True).raw)\r\n",
					"        img = img.resize((224, 224), Image.ANTIALIAS)\r\n",
					"        image = np.array(img)\r\n",
					"        queue.put(image)\r\n",
					"    except:\r\n",
					"        queue.put(None)\r\n",
					"        \r\n",
					"def load_images(image_urls):\r\n",
					"    manager = mp.Manager()\r\n",
					"    queue = manager.Queue()\r\n",
					"    processes = []\r\n",
					"    \r\n",
					"    for url in image_urls:\r\n",
					"        process = mp.Process(target=load_image, args=(url, queue))\r\n",
					"        process.start()\r\n",
					"        processes.append(process)\r\n",
					"        \r\n",
					"    images = []\r\n",
					"    success_count = 0\r\n",
					"    failure_count = 0\r\n",
					"    \r\n",
					"    for _ in range(len(image_urls)):\r\n",
					"        image = queue.get()\r\n",
					"        if image is not None:\r\n",
					"            images.append(image)\r\n",
					"            success_count += 1\r\n",
					"        else:\r\n",
					"            failure_count += 1\r\n",
					"            \r\n",
					"    for process in processes:\r\n",
					"        process.join()\r\n",
					"        \r\n",
					"    train_data = np.stack(images)\r\n",
					"    \r\n",
					"    print(\"Successful loads:\", success_count)\r\n",
					"    print(\"Failed loads:\", failure_count)\r\n",
					"    \r\n",
					"    return train_data\r\n",
					""
				],
				"execution_count": 65
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import multiprocessing as mp\r\n",
					"\r\n",
					"def load_image_try(url):\r\n",
					"    response = requests.get(url)\r\n",
					"    img = Image.open(requests.get(url, stream=True).raw)\r\n",
					"    img = img.resize((224, 224), Image.ANTIALIAS)\r\n",
					"    image = np.array(img)\r\n",
					"\r\n",
					"df_train[\"image\"] = df_train[\"image_link\"].apply(load_image_try)\r\n",
					"df_train"
				],
				"execution_count": 66
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"labels_map = {\r\n",
					"    'empty': 0,\r\n",
					"    'human': 1,\r\n",
					"    'gazellegrants': 2,\r\n",
					"    'reedbuck': 3,\r\n",
					"    'dikdik': 4,\r\n",
					"    'zebra': 5,\r\n",
					"    'porcupine': 6,\r\n",
					"    'gazellethomsons': 7,\r\n",
					"    'hyenaspotted': 8,\r\n",
					"    'warthog': 9,\r\n",
					"    'impala': 10,\r\n",
					"    'elephant': 11,\r\n",
					"    'aardvark': 12,\r\n",
					"    'giraffe': 13,\r\n",
					"    'mongoose': 14,\r\n",
					"    'buffalo': 15,\r\n",
					"    'hartebeest': 16,\r\n",
					"    'guineafowl': 17,\r\n",
					"    'wildebeest': 18,\r\n",
					"    'leopard': 19,\r\n",
					"    'ostrich': 20,\r\n",
					"    'lionfemale': 21,\r\n",
					"    'koribustard': 22,\r\n",
					"    'otherbird': 23,\r\n",
					"    'cheetah': 24,\r\n",
					"    'honeybadger': 25,\r\n",
					"    'bushbuck': 26,\r\n",
					"    'jackal': 27,\r\n",
					"    'aardwolf': 28,\r\n",
					"    'hippopotamus': 29,\r\n",
					"    'hyenastriped': 30,\r\n",
					"    'hare': 31,\r\n",
					"    'baboon': 32,\r\n",
					"    'monkeyvervet': 33,\r\n",
					"    'batearedfox': 34,\r\n",
					"    'waterbuck': 35,\r\n",
					"    'secretarybird': 36,\r\n",
					"    'topi': 37,\r\n",
					"    'serval': 38,\r\n",
					"    'lionmale': 39,\r\n",
					"    'eland': 40,\r\n",
					"    'rodents': 41,\r\n",
					"    'wildcat': 42,\r\n",
					"    'civet': 43,\r\n",
					"    'genet': 44,\r\n",
					"    'zorilla': 45,\r\n",
					"    'caracal': 46,\r\n",
					"    'rhinoceros': 47,\r\n",
					"    'reptiles': 48,\r\n",
					"    'insectspider': 49,\r\n",
					"    'duiker': 50,\r\n",
					"    'cattle': 51,\r\n",
					"    'vulture': 52,\r\n",
					"    'steenbok': 53,\r\n",
					"    'bat': 54,\r\n",
					"    'fire': 55,\r\n",
					"    'hyenabrown': 56,\r\n",
					"    'wilddog': 57,\r\n",
					"    'kudu': 58,\r\n",
					"    'pangolin': 59,\r\n",
					"    'lioncub': 60\r\n",
					"}\r\n",
					"\r\n",
					"image_labels = ['empty', 'human', 'gazellegrants', 'reedbuck', 'dikdik', 'zebra', 'porcupine', 'gazellethomsons', 'hyenaspotted', 'warthog', 'impala', 'elephant', 'aardvark', 'giraffe', 'mongoose', 'buffalo', 'hartebeest', 'guineafowl', 'wildebeest', 'leopard', 'ostrich', 'lionfemale', 'koribustard', 'otherbird', 'cheetah', 'honeybadger', 'bushbuck', 'jackal', 'aardwolf', 'hippopotamus', 'hyenastriped', 'hare', 'baboon', 'monkeyvervet', 'batearedfox', 'waterbuck', 'secretarybird', 'topi', 'serval', 'lionmale', 'eland', 'rodents', 'wildcat', 'civet', 'genet', 'zorilla', 'caracal', 'rhinoceros', 'reptiles', 'insectspider', 'duiker', 'cattle', 'vulture', 'steenbok', 'bat', 'fire', 'hyenabrown', 'wilddog', 'kudu', 'pangolin', 'lioncub']\r\n",
					"\r\n",
					"\r\n",
					"     "
				],
				"execution_count": 67
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"train_data = load_images(train_sub_set)\r\n",
					"val_data = load_images(val_sub_set)\r\n",
					"     "
				],
				"execution_count": 68
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import numpy as np\r\n",
					"\r\n",
					"def one_hot_encode_labels(image_labels, labels_map):\r\n",
					"    # Convert the label names to integers using the labels_map dictionary\r\n",
					"    label_ints = [labels_map[label] for label in image_labels]\r\n",
					"    # Perform one-hot encoding using np.eye\r\n",
					"    train_labels = np.eye(len(labels_map))[label_ints]\r\n",
					"    return train_labels\r\n",
					"\r\n",
					"train_labels = one_hot_encode_labels(image_labels, labels_map)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"train_labels"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pip install --upgrade tensorflow==2.9"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_train"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from tensorflow.keras.utils import Sequence\r\n",
					"\r\n",
					"class ArrayDataGenerator(Sequence):\r\n",
					"    def __init__(self, x, y, batch_size):\r\n",
					"        self.x = x\r\n",
					"        self.y = y\r\n",
					"        self.batch_size = batch_size\r\n",
					"\r\n",
					"    def __len__(self):\r\n",
					"        return int(np.ceil(len(self.x) / float(self.batch_size)))\r\n",
					"\r\n",
					"    def __getitem__(self, idx):\r\n",
					"        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n",
					"        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n",
					"        return batch_x, batch_y\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# import keras\r\n",
					"import tensorflow.keras\r\n",
					"from tensorflow.keras.applications import ResNet50\r\n",
					"from tensorflow.keras.applications import resnet\r\n",
					"model = resnet.ResNet50\r\n",
					"from tensorflow.keras.preprocessing import image\r\n",
					"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\r\n",
					"from tensorflow.keras.optimizers import SGD\r\n",
					"from tensorflow.keras.models import Model\r\n",
					"from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
					"\r\n",
					"num_classes = 59\r\n",
					"# Load the ResNet50 model pre-trained on ImageNet\r\n",
					"resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\r\n",
					"\r\n",
					"# Freeze all layers of the pre-trained model\r\n",
					"for layer in resnet_model.layers:\r\n",
					"    layer.trainable = False\r\n",
					"\r\n",
					"# Add new trainable layers on top of the frozen layers\r\n",
					"x = resnet_model.output\r\n",
					"x = GlobalAveragePooling2D()(x)\r\n",
					"x = Dense(1024, activation='relu')(x)\r\n",
					"x = Dense(512, activation='relu')(x)\r\n",
					"predictions = Dense(num_classes, activation='softmax')(x)\r\n",
					"\r\n",
					"# Compile the model\r\n",
					"model = Model(inputs=resnet_model.input, outputs=predictions)\r\n",
					"model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
					"\r\n",
					"# Create ImageDataGenerator objects for the training and validation sets\r\n",
					"train_datagen = ImageDataGenerator(rescale=1./255)\r\n",
					"val_datagen = ImageDataGenerator(rescale=1./255)\r\n",
					"            \r\n",
					"            \r\n",
					"# Use the flow_from_dataframe method to load the data\r\n",
					"train_generator = ArrayDataGenerator(train_data, train_labels, 32)\r\n",
					"\r\n",
					"val_generator = ArrayDataGenerator(val_data, val_labels, 32)\r\n",
					"\r\n",
					"# Compile the model\r\n",
					"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
					"\r\n",
					"# Train the model\r\n",
					"model.fit(train_generator, epochs=10, steps_per_epoch=100)"
				],
				"execution_count": null
			}
		]
	}
}